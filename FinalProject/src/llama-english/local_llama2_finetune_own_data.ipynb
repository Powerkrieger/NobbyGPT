{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This is a script found somewhere utilising a local copy of llama2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# You only need to run this once per machine\n",
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install -q -U datasets scipy ipywidgets matplotlib\n",
    "!pip install sentencepiece"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T16:26:00.589185088Z",
     "start_time": "2023-12-17T16:25:30.630024913Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-recipes in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (0.0.1)\r\n",
      "Requirement already satisfied: transformers in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (4.37.0.dev0)\r\n",
      "Requirement already satisfied: datasets in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (2.15.0)\r\n",
      "Requirement already satisfied: accelerate in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (0.25.0.dev0)\r\n",
      "Requirement already satisfied: sentencepiece in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (0.1.99)\r\n",
      "Requirement already satisfied: protobuf==3.20 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (3.20.0)\r\n",
      "Requirement already satisfied: py7zr in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (0.20.8)\r\n",
      "Requirement already satisfied: scipy in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (1.11.4)\r\n",
      "Requirement already satisfied: peft in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (0.7.2.dev0)\r\n",
      "Requirement already satisfied: bitsandbytes in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (0.41.3.post2)\r\n",
      "Requirement already satisfied: fire in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (0.5.0)\r\n",
      "Requirement already satisfied: torch_tb_profiler in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (0.4.3)\r\n",
      "Requirement already satisfied: ipywidgets in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (8.1.1)\r\n",
      "Requirement already satisfied: appdirs in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from llama-recipes) (1.4.4)\r\n",
      "Requirement already satisfied: black in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from llama-recipes) (23.12.0)\r\n",
      "Requirement already satisfied: loralib in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from llama-recipes) (0.1.2)\r\n",
      "Requirement already satisfied: optimum in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from llama-recipes) (1.16.1)\r\n",
      "Requirement already satisfied: torch>=2.0.1 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from llama-recipes) (2.1.2)\r\n",
      "Requirement already satisfied: filelock in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from transformers) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from transformers) (0.19.4)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from transformers) (1.26.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from transformers) (23.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from transformers) (2023.10.3)\r\n",
      "Requirement already satisfied: requests in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from transformers) (0.15.0)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from transformers) (0.4.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from transformers) (4.66.1)\r\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from datasets) (14.0.1)\r\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from datasets) (0.6)\r\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from datasets) (0.3.7)\r\n",
      "Requirement already satisfied: pandas in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from datasets) (2.1.4)\r\n",
      "Requirement already satisfied: xxhash in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from datasets) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from datasets) (0.70.15)\r\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\r\n",
      "Requirement already satisfied: aiohttp in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from datasets) (3.9.1)\r\n",
      "Requirement already satisfied: psutil in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from accelerate) (5.9.7)\r\n",
      "Requirement already satisfied: texttable in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from py7zr) (1.7.0)\r\n",
      "Requirement already satisfied: pycryptodomex>=3.16.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from py7zr) (3.19.0)\r\n",
      "Requirement already satisfied: pyzstd>=0.15.9 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from py7zr) (0.15.9)\r\n",
      "Requirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from py7zr) (1.1.0)\r\n",
      "Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from py7zr) (1.0.2)\r\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from py7zr) (0.2.3)\r\n",
      "Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from py7zr) (1.0.0)\r\n",
      "Requirement already satisfied: brotli>=1.1.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from py7zr) (1.1.0)\r\n",
      "Requirement already satisfied: six in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from fire) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from fire) (2.4.0)\r\n",
      "Requirement already satisfied: tensorboard!=2.1.0,>=1.15 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from torch_tb_profiler) (2.15.1)\r\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from ipywidgets) (0.2.0)\r\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from ipywidgets) (8.18.1)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from ipywidgets) (5.14.0)\r\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from ipywidgets) (4.0.9)\r\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from ipywidgets) (3.0.9)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\r\n",
      "Requirement already satisfied: decorator in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\r\n",
      "Requirement already satisfied: matplotlib-inline in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\r\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\r\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\r\n",
      "Requirement already satisfied: stack-data in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from requests->transformers) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from requests->transformers) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from requests->transformers) (2023.11.17)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (2.0.0)\r\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (1.60.0)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (2.25.2)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (1.2.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (3.5.1)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (68.2.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (3.0.1)\r\n",
      "Requirement already satisfied: sympy in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from torch>=2.0.1->llama-recipes) (1.12)\r\n",
      "Requirement already satisfied: networkx in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from torch>=2.0.1->llama-recipes) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from torch>=2.0.1->llama-recipes) (3.1.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from torch>=2.0.1->llama-recipes) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from torch>=2.0.1->llama-recipes) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from torch>=2.0.1->llama-recipes) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from torch>=2.0.1->llama-recipes) (8.9.2.26)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from torch>=2.0.1->llama-recipes) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from torch>=2.0.1->llama-recipes) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from torch>=2.0.1->llama-recipes) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from torch>=2.0.1->llama-recipes) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from torch>=2.0.1->llama-recipes) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from torch>=2.0.1->llama-recipes) (2.18.1)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from torch>=2.0.1->llama-recipes) (12.1.105)\r\n",
      "Requirement already satisfied: triton==2.1.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from torch>=2.0.1->llama-recipes) (2.1.0)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.1->llama-recipes) (12.3.101)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from black->llama-recipes) (8.1.7)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from black->llama-recipes) (1.0.0)\r\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from black->llama-recipes) (0.12.1)\r\n",
      "Requirement already satisfied: platformdirs>=2 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from black->llama-recipes) (4.1.0)\r\n",
      "Requirement already satisfied: tokenize-rt>=3.2.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from black[jupyter]->llama-recipes) (5.2.0)\r\n",
      "Requirement already satisfied: coloredlogs in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from optimum->llama-recipes) (15.0.1)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (5.3.2)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (0.3.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (1.3.1)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.12)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (2.1.3)\r\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from coloredlogs->optimum->llama-recipes) (10.0)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\r\n",
      "Requirement already satisfied: pure-eval in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from sympy->torch>=2.0.1->llama-recipes) (1.3.0)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (0.5.1)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/mighty/PycharmProjects/NobbyGPT/venv/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (3.2.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-recipes transformers datasets accelerate sentencepiece protobuf==3.20 py7zr scipy peft bitsandbytes fire torch_tb_profiler ipywidgets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T17:32:52.908442256Z",
     "start_time": "2023-12-17T17:32:50.051287041Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get access to llama license\n",
    "Clone Repo from huggingface site - supply huggingface access token\n",
    "-> git large file storage can be utilized\n",
    "Clone llama-recipes repository "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05H5MIfjyRgc"
   },
   "source": [
    "### 0. Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TEzYBadkyRgd",
    "ExecuteTime": {
     "end_time": "2023-12-17T17:09:09.997962901Z",
     "start_time": "2023-12-17T17:09:08.476932042Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up the Accelerator. I’m not sure if we really need this for a QLoRA given its description (I have to read more about it) but it seems it can’t hurt, and it’s helpful to have the code for future reference. You can always comment out the accelerator if you want to try without.\n",
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shz8Xdv-yRgf"
   },
   "source": [
    "### 1. Load Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "old config, mby good for loading model in google colab?\n",
    "model_id=\"./models_hf/7B\"  # `meta-llama/Llama-2-7b-hf`\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
    "model =LlamaForCausalLM.from_pretrained(model_id, load_in_8bit=True, device_map='auto', torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "E0Nl5mWL0k2T",
    "ExecuteTime": {
     "end_time": "2023-12-17T17:09:17.645143459Z",
     "start_time": "2023-12-17T17:09:12.135606182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67f4d0e13d9a44cba126bde16f84a25d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"../../../model/Llama-2-7b-hf\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "haSUDD9HyRgf",
    "ExecuteTime": {
     "end_time": "2023-12-17T17:31:45.669779233Z",
     "start_time": "2023-12-17T17:31:45.218991200Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(formatting_func(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What kind of fish is the best?  nobody wants to be the first one to give up.\n",
      "If you are a parent, you probably feel the same way.\n",
      "And you are not alone.\n",
      "The last thing you want to do is to be the first one to give up.\n",
      "You want to keep going, no matter what.\n",
      "You want to be the one who makes it.\n",
      "You want to be the one who wins.\n",
      "And you want to be the one who is remembered.\n",
      "But sometimes, you need to let go.\n",
      "You need to give up.\n",
      "You need to know when to stop.\n",
      "You need to know when to give in.\n",
      "And you need to know when to give up.\n",
      "And sometimes, that’s the hardest thing to do.\n",
      "And that’s what I’m here to tell you.\n",
      "You are not alone. You are not the only one who feels this way.\n",
      "And you are not the only one who wants to be the first one to give up.\n",
      "So don’t give up. Keep going.\n",
      "You are the one who is going to make it.\n",
      "You are the one who is going to win.\n",
      "You are the one who is going to be remembered.\n",
      "And you are\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \" What kind of fish is the best? \"\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=256, pad_token_id=2)[0], skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T17:31:58.507745472Z",
     "start_time": "2023-12-17T17:31:46.496068067Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Load Dataset"
   ],
   "metadata": {
    "id": "QcE4NTeFyRgd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's where you load your own data. You want the data formatted in a `.jsonl` file, structured something like this:"
   ],
   "metadata": {
    "id": "FCc64bfnmd3j"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Preparing data\n",
    "\n",
    "To prepare your dataset for loading, all you need is a `.jsonl` file structured something like this:\n",
    "```\n",
    "{\"input\": \"What color is the sky?\", \"output\": \"The sky is blue.\"}\n",
    "{\"input\": \"Where is the best place to get cloud GPUs?\", \"output\": \"Brev.dev\"}\n",
    "```\n",
    "\n",
    "If you choose to model your data as input/output pairs, you'll want to use something like the second `formatting_func` below, which will will combine all your features into one input string.\n"
   ],
   "metadata": {
    "id": "w1N2kdHsmkmR"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset('json', data_files='notes.jsonl', split='train')\n",
    "eval_dataset = load_dataset('json', data_files='notes_validation.jsonl', split='train')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Formatting prompts\n",
    "Then create a formatting_func to structure training examples as prompts. In my case, my data was just notes like this:\n",
    "\n",
    "```json\n",
    "{\"note\": \"note-for-model-to-predict\"}\n",
    "{\"note\": \"note-for-model-to-predict-1\"}\n",
    "{\"note\": \"note-for-model-to-predict-2\"}\n",
    "```\n",
    "So the formatting_func I used was:\n",
    "```python\n",
    "def formatting_func(example):\n",
    "    text = f\"### The following is a note by Eevee the Dog: {example['note']}\"\n",
    "    return text\n",
    "```"
   ],
   "metadata": {
    "id": "NQ7kW6zdmkmS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Tokenization\n",
    "\n",
    "Set up the tokenizer. Add padding on the left as it [makes training use less memory](https://ai.stackexchange.com/questions/41485/while-fine-tuning-a-decoder-only-llm-like-llama-on-chat-dataset-what-kind-of-pa).\n",
    "\n",
    "\n",
    "For `model_max_length`, it's helpful to get a distribution of your data lengths. Let's first tokenize without the truncation/padding, so we can get a length distribution."
   ],
   "metadata": {
    "id": "UjNdXolqyRgf"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    text = f\"### Question: {example['input_ids']}\\n ### Answer: {example['labels']}\"\n",
    "    return text"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T15:13:13.339178991Z",
     "start_time": "2023-12-17T15:13:13.306761504Z"
    },
    "id": "Vp5Gl7YcmkmT"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHnKLcq4yRgg"
   },
   "source": [
    "Reformat the prompt and tokenize each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T15:13:38.186256084Z",
     "start_time": "2023-12-17T15:13:17.471989390Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54c21671bf2466f9eeb4fa2d08d87fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbac1287782e4ec8b8fdeaed08abc862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72512305f01b46a38992fa05950c15ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74bfd4ad6c5444b595729726ec2c2ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3058b39c8e4dcc9c8b8d6a55c46e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1047350e74b4588a5230a6d84b26ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = supply_train_dataset_in_original_form\n",
    "eval_dataset = supply_validation_dataset_in_original_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd15cd7b913c499cb4c95d42f879e665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1562 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a77147084e444bd8f7e11b0d3e334b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtqWK49TmkmV"
   },
   "source": [
    "Let's get a distribution of our dataset lengths, so we can determine the appropriate `max_length` for our input tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T15:15:23.011182851Z",
     "start_time": "2023-12-17T15:14:59.619174014Z"
    },
    "id": "pRoItZu-mkmV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1646\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenize_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBk4Qp_vyRgh"
   },
   "source": [
    "From here, you can choose where you'd like to set the `max_length` to be. You can truncate and pad training examples to fit them to your chosen size. Be aware that choosing a larger `max_length` has its compute tradeoffs.\n",
    "\n",
    "I'm using my personal notes to train the model, and they vary greatly in length. I spent some time cleaning the dataset so the samples were about the same length, cutting up individual notes if needed, but being sure to not cut in the middle of a word or sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RG8beiojmkmW"
   },
   "source": [
    "Now let's tokenize again with padding and truncation, and set up the tokenize function to make labels and input_ids the same. This is basically what [self-supervised fine-tuning is](https://neptune.ai/blog/self-supervised-learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T15:20:17.226086547Z",
     "start_time": "2023-12-17T15:20:17.182007859Z"
    },
    "id": "fHkHfaxxmkmW"
   },
   "outputs": [],
   "source": [
    "max_length = 512 # This was an appropriate max length for my dataset\n",
    "\n",
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        formatting_func(prompt),\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T15:21:17.032165656Z",
     "start_time": "2023-12-17T15:20:19.330897316Z"
    },
    "id": "m711Ls91mkmW"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73cddf9fb6f2414dab0bddc066081ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1562 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1306ebeb853a44d28ed17ba4493d1a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQL796OayRgh"
   },
   "source": [
    "Check that `input_ids` is padded on the left with the `eos_token` (2) and there is an `eos_token` 2 added to the end, and the prompt starts with a `bos_token` (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T15:22:01.307801470Z",
     "start_time": "2023-12-17T15:22:01.233474586Z"
    },
    "id": "uCFzwBd7mkmW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 835, 894, 29901, 518, 29906, 29953, 29906, 29947, 29929, 29892, 29871, 29906, 29929, 29929, 29900, 29896, 29892, 29871, 29896, 29941, 29892, 29871, 29941, 29955, 29947, 29906, 29892, 29871, 29947, 29900, 29896, 29892, 29871, 29896, 29900, 29955, 29945, 29941, 29892, 29871, 29941, 29900, 29946, 29892, 29871, 29945, 29947, 29955, 29900, 29892, 29871, 29906, 29929, 29947, 29929, 29906, 29892, 29871, 29945, 29946, 29900, 29892, 29871, 29906, 29941, 29906, 29947, 29941, 29892, 29871, 29953, 29955, 29900, 29892, 29871, 29946, 29929, 29947, 29906, 29892, 29871, 29906, 29929, 29947, 29929, 29906, 29892, 29871, 29896, 29941, 29953, 29941, 29892, 29871, 29953, 29955, 29900, 29892, 29871, 29906, 29947, 29929, 29892, 29871, 29906, 29906, 29900, 29929, 29892, 29871, 29946, 29955, 29896, 29892, 29871, 29906, 29953, 29941, 29892, 29871, 29906, 29955, 29900, 29892, 29871, 29947, 29953, 29900, 29892, 29871, 29906, 29929, 29947, 29947, 29929, 29892, 29871, 29906, 29892, 29871, 29906, 29892, 29871, 29896, 29892, 29871, 29953, 29929, 29929, 29896, 29892, 29871, 29941, 29900, 29941, 29946, 29892, 29871, 29953, 29955, 29945, 29892, 29871, 29946, 29946, 29945, 29892, 29871, 29955, 29929, 29906, 29947, 29892, 29871, 29906, 29929, 29929, 29900, 29896, 29892, 29871, 29896, 29941, 29892, 29871, 29906, 29929, 29929, 29906, 29946, 29892, 29871, 29896, 29896, 29941, 29896, 29892, 29871, 29906, 29929, 29929, 29900, 29896, 29892, 29871, 29896, 29929, 29941, 29947, 29892, 29871, 29941, 29953, 29953, 29892, 29871, 29947, 29953, 29946, 29892, 29871, 29941, 29900, 29946, 29892, 29871, 29955, 29946, 29947, 29892, 29871, 29941, 29953, 29941, 29892, 29871, 29906, 29953, 29941, 29945, 29892, 29871, 29906, 29929, 29929, 29955, 29941, 29892, 29871, 29941, 29900, 29900, 29900, 29946, 29892, 29871, 29896, 29941, 29892, 29871, 29896, 29946, 29955, 29953, 29929, 29892, 29871, 29946, 29945, 29896, 29945, 29892, 29871, 29906, 29929, 29929, 29900, 29896, 29892, 29871, 29941, 29929, 29929, 29892, 29871, 29941, 29946, 29900, 29892, 29871, 29906, 29929, 29929, 29929, 29896, 29892, 29871, 29947, 29947, 29955, 29892, 29871, 29896, 29906, 29953, 29906, 29946, 29892, 29871, 29945, 29929, 29906, 29892, 29871, 29955, 29896, 29946, 29892, 29871, 29946, 29896, 29896, 29892, 29871, 29946, 29946, 29945, 29892, 29871, 29896, 29896, 29941, 29929, 29892, 29871, 29929, 29947, 29896, 29896, 29892, 29871, 29906, 29906, 29929, 29929, 29941, 29892, 29871, 29896, 29941, 29892, 29871, 29906, 29929, 29929, 29906, 29946, 29892, 29871, 29896, 29896, 29941, 29896, 29892, 29871, 29906, 29929, 29929, 29900, 29896, 29892, 29871, 29941, 29955, 29945, 29900, 29892, 29871, 29906, 29929, 29929, 29955, 29941, 29892, 29871, 29941, 29900, 29900, 29900, 29946, 29892, 29871, 29896, 29941, 29892, 29871, 29896, 29946, 29955, 29953, 29929, 29892, 29871, 29946, 29945, 29896, 29945, 29892, 29871, 29906, 29929, 29929, 29900, 29896, 29892, 29871, 29941, 29900, 29953, 29892, 29871, 29941, 29955, 29953, 29941, 29892, 29871, 29941, 29906, 29947, 29906, 29892, 29871, 29906, 29929, 29929, 29896, 29945, 29892, 29871, 29906, 29929, 29947, 29955, 29941, 29892, 29871, 29906, 29896, 29946, 29929, 29892, 29871, 29946, 29946, 29945, 29892, 29871, 29945, 29896, 29945, 29892, 29871, 29941, 29953, 29953, 29892, 29871, 29906, 29906, 29929, 29929, 29941, 29892, 29871, 29896, 29941, 29892, 29871, 29906, 29929, 29929, 29906, 29946, 29892, 29871, 29896, 29896, 29941, 29896, 29892, 29871, 29906, 29929, 29929, 29900, 29896, 29892, 29871, 29945, 29953, 29955, 29946, 29892, 29871, 29906, 29929, 29947, 29929, 29906, 2]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset[1]['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8Qqq2E0mkmX"
   },
   "source": [
    "Now all the samples should be the same length, `max_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T15:22:33.274717168Z",
     "start_time": "2023-12-17T15:22:32.340840075Z"
    },
    "id": "eLEukiAVmkmX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1646\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFpeDgWJmkmX"
   },
   "source": [
    "### How does the base model do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vxbl4ACsyRgi"
   },
   "source": [
    "Optionally, you can check how Llama 2 7B does on one of your data samples. For example, if you have a dataset of users' biometric data to their health scores, you could test the following `eval_prompt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T15:22:39.822230728Z",
     "start_time": "2023-12-17T15:22:39.774265235Z"
    },
    "id": "gOxnx-cAyRgi"
   },
   "outputs": [],
   "source": [
    "eval_prompt = \"\"\" Given the following biometric data, score the users' health, from 0-100.\n",
    "\n",
    "### Biometric Data:\n",
    "Temperature=98.2,\n",
    "Sex=F,\n",
    "Age=29,\n",
    "Height=69 inches,\n",
    "Weight=160 lbs,\n",
    "V02_Max=55,\n",
    "HRV=55\n",
    "\n",
    "### Health Score:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODyKB5drmkmb"
   },
   "source": [
    "The `eval_prompt` I used was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T15:22:59.156518421Z",
     "start_time": "2023-12-17T15:22:47.356564202Z"
    },
    "id": "NidIuFXMyRgi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The following is a note by Eevee the Dog: #  everybody's free (to wear sunscreen)\n",
      "I'm going to be a little self-indulgent and post a few pictures of my kids. I'm not doing it for my own benefit, but rather to share the joy of a father's pride.\n",
      "The first picture is of my daughter, who is 16 years old and a high school junior. She has been a dancer since she was 3 years old, and has been dancing with the same studio since then. She has worked very hard to achieve her current level of dance, and she has done it all on her own. She has never had a private lesson, and she has never had a parent helping her with her homework. She has been a very independent child since she was very young, and she has always been very good at making her own decisions. She has a very strong work ethic, and she is always willing to put in the time and effort to be the best she can be.\n",
      "The second picture is of my son, who is 13 years old and a middle schooler. He has been a dancer since he was 2 years old, and has been dancing with the same studio since then\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \" The following is a note by Eevee the Dog: # \"\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=256, pad_token_id=2)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCAWeCzZyRgi"
   },
   "source": [
    "Observe how the model does out of the box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AapDoyfAyRgi"
   },
   "source": [
    "### 4. Set Up LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mp2gMi1ZzGET"
   },
   "source": [
    "Now, to start our fine-tuning, we have to apply some preprocessing to the model to prepare it for training. For that use the `prepare_model_for_kbit_training` method from PEFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T15:23:36.676483659Z",
     "start_time": "2023-12-17T15:23:36.643407757Z"
    },
    "id": "a9EUEDAl0ss3"
   },
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T15:23:37.958214986Z",
     "start_time": "2023-12-17T15:23:37.886121114Z"
    },
    "id": "gkIcwsSU01EB"
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUYEpEK-yRgj"
   },
   "source": [
    "Let's print the model to examine its layers, as we will apply QLoRA to all the linear layers of the model. Those layers are `q_proj`, `k_proj`, `v_proj`, `o_proj`, `gate_proj`, `up_proj`, `down_proj`, and `lm_head`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T15:23:39.535772174Z",
     "start_time": "2023-12-17T15:23:39.525432665Z"
    },
    "id": "XshGNsbxyRgj",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6mTLuQJyRgj"
   },
   "source": [
    "Here we define the LoRA config.\n",
    "\n",
    "`r` is the rank of the low-rank matrix used in the adapters, which thus controls the number of parameters trained. A higher rank will allow for more expressivity, but there is a compute tradeoff.\n",
    "\n",
    "`alpha` is the scaling factor for the learned weights. The weight matrix is scaled by `alpha/r`, and thus a higher value for `alpha` assigns more weight to the LoRA activations.\n",
    "\n",
    "The values used in the QLoRA paper were `r=64` and `lora_alpha=16`, and these are said to generalize well, but we will use `r=32` and `lora_alpha=64` so that we have more emphasis on the new fine-tuned data while also reducing computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T15:24:09.145368138Z",
     "start_time": "2023-12-17T15:24:07.733019026Z"
    },
    "id": "Ybeyl20n3dYH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 81108992 || all params: 3581521920 || trainable%: 2.264651559077991\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)\n",
    "\n",
    "# Apply the accelerator. You can comment this out to remove the accelerator.\n",
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_FHi_VLyRgn"
   },
   "source": [
    "See how the model looks different now, with the LoRA adapters added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T15:24:14.648374448Z",
     "start_time": "2023-12-17T15:24:14.590978115Z"
    },
    "id": "IaYMWak4yRgn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): PeftModelForCausalLM(\n",
      "      (base_model): LoraModel(\n",
      "        (model): PeftModelForCausalLM(\n",
      "          (base_model): LoraModel(\n",
      "            (model): LlamaForCausalLM(\n",
      "              (model): LlamaModel(\n",
      "                (embed_tokens): Embedding(32000, 4096)\n",
      "                (layers): ModuleList(\n",
      "                  (0-31): 32 x LlamaDecoderLayer(\n",
      "                    (self_attn): LlamaSdpaAttention(\n",
      "                      (q_proj): lora.Linear4bit(\n",
      "                        (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                        (lora_dropout): ModuleDict(\n",
      "                          (default): Dropout(p=0.05, inplace=False)\n",
      "                        )\n",
      "                        (lora_A): ModuleDict(\n",
      "                          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                        )\n",
      "                        (lora_B): ModuleDict(\n",
      "                          (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                        )\n",
      "                        (lora_embedding_A): ParameterDict()\n",
      "                        (lora_embedding_B): ParameterDict()\n",
      "                      )\n",
      "                      (k_proj): lora.Linear4bit(\n",
      "                        (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                        (lora_dropout): ModuleDict(\n",
      "                          (default): Dropout(p=0.05, inplace=False)\n",
      "                        )\n",
      "                        (lora_A): ModuleDict(\n",
      "                          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                        )\n",
      "                        (lora_B): ModuleDict(\n",
      "                          (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                        )\n",
      "                        (lora_embedding_A): ParameterDict()\n",
      "                        (lora_embedding_B): ParameterDict()\n",
      "                      )\n",
      "                      (v_proj): lora.Linear4bit(\n",
      "                        (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                        (lora_dropout): ModuleDict(\n",
      "                          (default): Dropout(p=0.05, inplace=False)\n",
      "                        )\n",
      "                        (lora_A): ModuleDict(\n",
      "                          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                        )\n",
      "                        (lora_B): ModuleDict(\n",
      "                          (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                        )\n",
      "                        (lora_embedding_A): ParameterDict()\n",
      "                        (lora_embedding_B): ParameterDict()\n",
      "                      )\n",
      "                      (o_proj): lora.Linear4bit(\n",
      "                        (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                        (lora_dropout): ModuleDict(\n",
      "                          (default): Dropout(p=0.05, inplace=False)\n",
      "                        )\n",
      "                        (lora_A): ModuleDict(\n",
      "                          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                        )\n",
      "                        (lora_B): ModuleDict(\n",
      "                          (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                        )\n",
      "                        (lora_embedding_A): ParameterDict()\n",
      "                        (lora_embedding_B): ParameterDict()\n",
      "                      )\n",
      "                      (rotary_emb): LlamaRotaryEmbedding()\n",
      "                    )\n",
      "                    (mlp): LlamaMLP(\n",
      "                      (gate_proj): lora.Linear4bit(\n",
      "                        (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "                        (lora_dropout): ModuleDict(\n",
      "                          (default): Dropout(p=0.05, inplace=False)\n",
      "                        )\n",
      "                        (lora_A): ModuleDict(\n",
      "                          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                        )\n",
      "                        (lora_B): ModuleDict(\n",
      "                          (default): Linear(in_features=32, out_features=11008, bias=False)\n",
      "                        )\n",
      "                        (lora_embedding_A): ParameterDict()\n",
      "                        (lora_embedding_B): ParameterDict()\n",
      "                      )\n",
      "                      (up_proj): lora.Linear4bit(\n",
      "                        (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "                        (lora_dropout): ModuleDict(\n",
      "                          (default): Dropout(p=0.05, inplace=False)\n",
      "                        )\n",
      "                        (lora_A): ModuleDict(\n",
      "                          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                        )\n",
      "                        (lora_B): ModuleDict(\n",
      "                          (default): Linear(in_features=32, out_features=11008, bias=False)\n",
      "                        )\n",
      "                        (lora_embedding_A): ParameterDict()\n",
      "                        (lora_embedding_B): ParameterDict()\n",
      "                      )\n",
      "                      (down_proj): lora.Linear4bit(\n",
      "                        (base_layer): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
      "                        (lora_dropout): ModuleDict(\n",
      "                          (default): Dropout(p=0.05, inplace=False)\n",
      "                        )\n",
      "                        (lora_A): ModuleDict(\n",
      "                          (default): Linear(in_features=11008, out_features=32, bias=False)\n",
      "                        )\n",
      "                        (lora_B): ModuleDict(\n",
      "                          (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                        )\n",
      "                        (lora_embedding_A): ParameterDict()\n",
      "                        (lora_embedding_B): ParameterDict()\n",
      "                      )\n",
      "                      (act_fn): SiLU()\n",
      "                    )\n",
      "                    (input_layernorm): LlamaRMSNorm()\n",
      "                    (post_attention_layernorm): LlamaRMSNorm()\n",
      "                  )\n",
      "                )\n",
      "                (norm): LlamaRMSNorm()\n",
      "              )\n",
      "              (lm_head): lora.Linear(\n",
      "                (base_layer): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=32000, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9KNTJZkyRgn"
   },
   "source": [
    "\n",
    "Let's use Weights & Biases to track our training metrics. You'll need to apply an API key when prompted. Feel free to skip this if you'd like, and just comment out the `wandb` parameters in the `Trainer` definition below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T15:26:06.734181073Z",
     "start_time": "2023-12-17T15:24:18.233791061Z"
    },
    "id": "DDqUNyIoyRgo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/mighty/.netrc\n"
     ]
    }
   ],
   "source": [
    "!pip install -q wandb -U\n",
    "\n",
    "import wandb, os\n",
    "wandb.login()\n",
    "\n",
    "wandb_project = \"journal-finetune\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0MOtwf3zdZp"
   },
   "source": [
    "### 5. Run Training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEe0uWYSyRgo"
   },
   "source": [
    "I didn't have a lot of training samples, so I used only 500 steps. I found that the end product worked well.\n",
    "\n",
    "A note on training. You can set the `max_steps` to be high initially, and examine at what step your model's performance starts to degrade. There is where you'll find a sweet spot for how many steps to perform. For example, say you start with 1000 steps, and find that at around 500 steps the model starts overfitting - the validation loss goes up (bad) while the training loss goes down significantly, meaning the model is learning the training set really well, but is unable to generalize to new datapoints. Therefore, 500 steps would be your sweet spot, so you would use the `checkpoint-500` model repo in your output dir (`llama2-7b-journal-finetune`) as your final model in step 6 below.\n",
    "\n",
    "You can interrupt the process via Kernel -> Interrupt Kernel in the top nav bar once you realize you didn't need to train anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T15:26:24.858683209Z",
     "start_time": "2023-12-17T15:26:24.802222668Z"
    },
    "id": "c_L1131GyRgo"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T16:00:37.809362087Z",
     "start_time": "2023-12-17T15:26:26.130397645Z"
    },
    "id": "jq0nX33BmfaC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mpowerkrieger\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mighty/PycharmProjects/llama-recipes/examples/wandb/run-20231217_162626-l3r6aouc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/powerkrieger/journal-finetune/runs/l3r6aouc' target=\"_blank\">llama2-7b-journal-finetune-2023-12-17-16-26</a></strong> to <a href='https://wandb.ai/powerkrieger/journal-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/powerkrieger/journal-finetune' target=\"_blank\">https://wandb.ai/powerkrieger/journal-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/powerkrieger/journal-finetune/runs/l3r6aouc' target=\"_blank\">https://wandb.ai/powerkrieger/journal-finetune/runs/l3r6aouc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mighty/PycharmProjects/llama-recipes/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/500 : < :, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mighty/PycharmProjects/llama-recipes/venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/mighty/PycharmProjects/llama-recipes/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/mighty/PycharmProjects/llama-recipes/venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/mighty/PycharmProjects/llama-recipes/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/mighty/PycharmProjects/llama-recipes/venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/mighty/PycharmProjects/llama-recipes/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/mighty/PycharmProjects/llama-recipes/venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/mighty/PycharmProjects/llama-recipes/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/mighty/PycharmProjects/llama-recipes/venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/mighty/PycharmProjects/llama-recipes/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/mighty/PycharmProjects/llama-recipes/venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/mighty/PycharmProjects/llama-recipes/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/mighty/PycharmProjects/llama-recipes/venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/mighty/PycharmProjects/llama-recipes/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/mighty/PycharmProjects/llama-recipes/venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/mighty/PycharmProjects/llama-recipes/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/mighty/PycharmProjects/llama-recipes/venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/mighty/PycharmProjects/llama-recipes/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/mighty/PycharmProjects/llama-recipes/venv/lib/python3.11/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.9441669921875, metrics={'train_runtime': 2051.3654, 'train_samples_per_second': 0.487, 'train_steps_per_second': 0.244, 'total_flos': 2.0546926411776e+16, 'train_loss': 0.9441669921875, 'epoch': 0.64})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"journal-finetune\"\n",
    "base_model_name = \"llama2-7b\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        gradient_checkpointing_kwargs={'use_reentrant':False}, # added because ofg warning, we will see\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=500,\n",
    "        learning_rate=2.5e-5, # Want a small lr for finetuning\n",
    "        bf16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_dir=\"./logs\",        # Directory for storing logs\n",
    "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        save_steps=50,                # Save checkpoints every 50 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=50,               # Evaluate and save checkpoints every 50 steps\n",
    "        do_eval=True,                # Perform evaluation at the end of training\n",
    "        report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D57XqcsyRgo"
   },
   "source": [
    "### 6. Drum Roll... Try the Trained Model!\n",
    "\n",
    "It's a good idea to kill the current process so that you don't run out of memory loading the base model again on top of the model we just trained. Go to `Kernel > Restart Kernel` or kill the process via the Terminal (`nvidia smi` > `kill [PID]`).\n",
    "\n",
    "By default, the PEFT library will only save the QLoRA adapters, so we need to first load the base Llama 2 7B model from the Huggingface Hub:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SKSnF016yRgp"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Llama 2 7B, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    use_auth_token=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BxOhAiqyRgp"
   },
   "source": [
    "Now load the QLoRA adapter from the appropriate checkpoint directory, i.e. the best performing model checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwsiqhWuyRgp"
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"llama2-7b-journal-finetune/checkpoint-500\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lX39ibolyRgp"
   },
   "source": [
    "and run your inference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUehsaVNyRgp"
   },
   "source": [
    "Let's try the same `eval_prompt` and thus `model_input` as above, and see if the new finetuned model performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMkVNEUvyRgp"
   },
   "outputs": [],
   "source": [
    "eval_prompt = \" The following is a note by Eevee the Dog, which doesn't share anything too personal: # \"\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCJnpZoayRgq"
   },
   "source": [
    "### Sweet... it worked! The fine-tuned model now prints out journal entries in my style!\n",
    "\n",
    "How funny to see it write like me as an angsty teenager.\n",
    "\n",
    "I hope you enjoyed this tutorial on fine-tuning Llama 2 on your own data. If you have any questions, feel free to reach out to me on [X](https://x.com/harperscarroll) or [Discord](https://discord.gg/NVDyv7TUgJ).\n",
    "\n",
    "🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙 🤙"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
